{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/Agenda2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Natural Language Processing (or NLP) is applying ML models to text <br>\n",
    "NLP is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to fruitfully process large amounts of natural language data <br> [wiki](https://en.wikipedia.org/wiki/Natural-language_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are getting error then install the curresponding packages <br> \n",
    "\n",
    "conda install package_name\n",
    "<img src=\"./images/conda_package_install.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "posData_SW = pd.read_csv('.\\dataset\\SW_Review\\md_software_positive_review.csv')\n",
    "negData_SW = pd.read_csv('.\\dataset\\SW_Review\\md_software_negative_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I am amazed what this program can do. It is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I concur with the review that points up the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Simply the best software out there for digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Adobe Photoshop has a long history of being th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I was afraid at first not to order directly fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Nobody, and I mean NObody, could be more of an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>If you're one of those people like me, who han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The product is easy to use.  Like how it inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I've been frustrated for quite some time now w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have been using Adobe Acrobat for a few year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This is a good inexpensive GPS system. It does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Its a great GPS once its starts and detects th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I used this program on a 5-state road trip of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This is my first experience with GPS.  This pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It does everything I hoped for and more!! As a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I bought this CD for my two grandchildren for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>This new Nancy Drew game was fun to play! It w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It took so long for this to come out...I hated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>These are a favorite in the home. Even though ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I really enjoy the Nancy Drew games. They can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Previously I owned ColorVision's Spyder2 progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I have read several reviews and decided the Sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I am very happy with it but it doesn't live up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The product has very good themes and screen sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Product came in a timely manner and I love it....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>extremely helpful and superior graphics and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This is an easy product to use.  It saves you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It's a useful tool. Combined with another Nort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It has some nice upgrades from version 6.  It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The new Adobe Acrobat has a cleaner look and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I only have the basic and its good but i've se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>5.0</td>\n",
       "      <td>If you're looking to create the next Doom 3 or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I give the DB Pro 5 stars, but I am totally di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Was using DataManager, but disliked the consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this software to transfer files and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The product does just what I want it to do.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Acronis True Image 10.0 Home is really great f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Poser user since Version 3.Poser continues to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>4.0</td>\n",
       "      <td>You will probably read 50/50 from the reviews ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>4.0</td>\n",
       "      <td>**things i liked about the programit supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The software was just what I expected and very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The program is over what I expected. Performan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Many more fonts to choose from -- an excellent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I like the way the program goes through the ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I started off using Turbotax this year, but re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this edition of TaxCut last week.  O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>5.0</td>\n",
       "      <td>my son is absolutely loves this dvd/games.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>4.0</td>\n",
       "      <td>my sister have been uesing it since i bought i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>4.0</td>\n",
       "      <td>It is a little bit clumsey. When I go to it, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This software is very user friendly,easy to in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It is wondeful software.  Simple, easy to use,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Compared to FP 2000 and earlier versions, it o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I purchased this software mainly for Web Desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Frontpage 2003 is a great, easy-to-use WYSIWYG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Given my limited knowledge of computer science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It was some years ago when I bought a previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The hard-copy of Britannica has been the stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I trust the information I find from Britannica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>If you want a simple to use program to manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have used Quicken for over 12 years.  Whenev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating                                    Review_Comments\n",
       "0       5.0  I am amazed what this program can do. It is a ...\n",
       "1       4.0  I concur with the review that points up the pr...\n",
       "2       5.0  Simply the best software out there for digital...\n",
       "3       5.0  Adobe Photoshop has a long history of being th...\n",
       "4       5.0  I was afraid at first not to order directly fr...\n",
       "5       4.0  Nobody, and I mean NObody, could be more of an...\n",
       "6       5.0  If you're one of those people like me, who han...\n",
       "7       5.0  The product is easy to use.  Like how it inter...\n",
       "8       4.0  I've been frustrated for quite some time now w...\n",
       "9       5.0  I have been using Adobe Acrobat for a few year...\n",
       "10      4.0  This is a good inexpensive GPS system. It does...\n",
       "11      4.0  Its a great GPS once its starts and detects th...\n",
       "12      4.0  I used this program on a 5-state road trip of ...\n",
       "13      5.0  This is my first experience with GPS.  This pr...\n",
       "14      5.0  It does everything I hoped for and more!! As a...\n",
       "15      4.0  I bought this CD for my two grandchildren for ...\n",
       "16      4.0  This new Nancy Drew game was fun to play! It w...\n",
       "17      4.0  It took so long for this to come out...I hated...\n",
       "18      5.0  These are a favorite in the home. Even though ...\n",
       "19      5.0  I really enjoy the Nancy Drew games. They can ...\n",
       "20      4.0  Previously I owned ColorVision's Spyder2 progr...\n",
       "21      4.0  I have read several reviews and decided the Sp...\n",
       "22      4.0  I am very happy with it but it doesn't live up...\n",
       "23      4.0  The product has very good themes and screen sa...\n",
       "24      5.0  Product came in a timely manner and I love it....\n",
       "25      5.0  extremely helpful and superior graphics and ch...\n",
       "26      5.0  This is an easy product to use.  It saves you ...\n",
       "27      4.0  It's a useful tool. Combined with another Nort...\n",
       "28      4.0  It has some nice upgrades from version 6.  It ...\n",
       "29      4.0  The new Adobe Acrobat has a cleaner look and f...\n",
       "..      ...                                                ...\n",
       "970     5.0  I only have the basic and its good but i've se...\n",
       "971     5.0  If you're looking to create the next Doom 3 or...\n",
       "972     5.0  I give the DB Pro 5 stars, but I am totally di...\n",
       "973     5.0  Was using DataManager, but disliked the consta...\n",
       "974     5.0  Purchased this software to transfer files and ...\n",
       "975     5.0  The product does just what I want it to do.  I...\n",
       "976     5.0  Acronis True Image 10.0 Home is really great f...\n",
       "977     5.0  Poser user since Version 3.Poser continues to ...\n",
       "978     4.0  You will probably read 50/50 from the reviews ...\n",
       "979     4.0  **things i liked about the programit supports ...\n",
       "980     5.0  The software was just what I expected and very...\n",
       "981     5.0  The program is over what I expected. Performan...\n",
       "982     5.0  Many more fonts to choose from -- an excellent...\n",
       "983     4.0  I like the way the program goes through the ta...\n",
       "984     4.0  I started off using Turbotax this year, but re...\n",
       "985     5.0  Purchased this edition of TaxCut last week.  O...\n",
       "986     5.0  my son is absolutely loves this dvd/games.  I ...\n",
       "987     4.0  my sister have been uesing it since i bought i...\n",
       "988     4.0  It is a little bit clumsey. When I go to it, i...\n",
       "989     5.0  This software is very user friendly,easy to in...\n",
       "990     5.0  It is wondeful software.  Simple, easy to use,...\n",
       "991     4.0  Compared to FP 2000 and earlier versions, it o...\n",
       "992     5.0  I purchased this software mainly for Web Desig...\n",
       "993     4.0  Frontpage 2003 is a great, easy-to-use WYSIWYG...\n",
       "994     4.0  Given my limited knowledge of computer science...\n",
       "995     5.0  It was some years ago when I bought a previous...\n",
       "996     5.0  The hard-copy of Britannica has been the stand...\n",
       "997     4.0  I trust the information I find from Britannica...\n",
       "998     4.0  If you want a simple to use program to manage ...\n",
       "999     5.0  I have used Quicken for over 12 years.  Whenev...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posData_SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The Easy Language 16 is only useful if you're ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>My boss asked me to get this, so that he check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I found this title messing around adding thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>They have the hebrew backwards!! You are suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I just bought and installed this CD with the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I just bought this cd because I am learning Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This dude is selling info that you can learn f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Imagine that you know so little about a comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>When I first installed the program I was able ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I installed a perfectly legal upgrade of Photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Im computer literate and regularly use a numbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This is the worst version of Adobe Illustrator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I assumed, incorrectly, that Adobe's customer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I use PDFs a lot and I must say that quite oft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This product could put user/customer's life at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>The only redeeming quality about this GPS syst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I rarely write reviews but I decided to write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I have used MS streets and trips 2005 and 2006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>There's a reason why this stuff is significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I was expecting a lot more from these two CD's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Acrobat 5 was so buggy that I thought I'd give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>This software didn't quite do what I expected....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Did not work with my apple computer,requested ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The computer I have now(about 500 Mhz)is faste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This is the first time I have ever reviewed a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I purchased this software thinking that I coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>By reading the cover I thought it would be a g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Warning! I resized my partition and when it re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I have to qualify this review by saying that I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I purchased Partition Magic 8.0 based on my pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>BE CAREFUL - If you buy this version of Symant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I Purchased this product in Nov 2006. Reviews ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This product is a huge waste of time.  It load...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.0</td>\n",
       "      <td>this software never worked after installation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This software is fine for altering digital pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.0</td>\n",
       "      <td>this product is extremely difficult to learn. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I received the bundle but there is no installa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>2.0</td>\n",
       "      <td>...buy it here and save $s!Shipping cost from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I installed Adobe 8.0 at the request of a clie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Please see reviews of the previous version 7.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>TaxCut did not warn me that I needed to fill o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This program has a bug in processing 1099-R da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I got the hang on the 21% and all they could t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Unfortunately, this application includes only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2.0</td>\n",
       "      <td>This dictionary is not for the person who Engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I was thoroughly disappointed.  The first few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This is the worst thing I have ever bought. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Although this dictionary's contents are extens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been using FrontPage since 1997.  I am ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I am not a 'professional,' but figured out how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I gave this a 2nd star for a support call ms p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Have tried about six times to install it.  I'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>1.0</td>\n",
       "      <td>i am underwhelmed with the dvd-rom from britan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>1.0</td>\n",
       "      <td>EB own words: \"Unfortunately, at this time the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Since most of the complaints are from recent s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I've been using Quicken for Windows for years....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Intuit charges banks extra to support Mac user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I purchased this product thinking that it woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I've been using Quicken for over a decade, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to agree with all these reviews already...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating                                    Review_Comments\n",
       "0       2.0  The Easy Language 16 is only useful if you're ...\n",
       "1       1.0  My boss asked me to get this, so that he check...\n",
       "2       1.0  I found this title messing around adding thing...\n",
       "3       1.0  They have the hebrew backwards!! You are suppo...\n",
       "4       2.0  I just bought and installed this CD with the h...\n",
       "5       2.0  I just bought this cd because I am learning Ha...\n",
       "6       1.0  This dude is selling info that you can learn f...\n",
       "7       1.0  Imagine that you know so little about a comput...\n",
       "8       2.0  When I first installed the program I was able ...\n",
       "9       1.0  I installed a perfectly legal upgrade of Photo...\n",
       "10      2.0  Im computer literate and regularly use a numbe...\n",
       "11      1.0  This is the worst version of Adobe Illustrator...\n",
       "12      1.0  I assumed, incorrectly, that Adobe's customer ...\n",
       "13      2.0  I use PDFs a lot and I must say that quite oft...\n",
       "14      1.0  This product could put user/customer's life at...\n",
       "15      1.0  The only redeeming quality about this GPS syst...\n",
       "16      1.0  I rarely write reviews but I decided to write ...\n",
       "17      1.0  I have used MS streets and trips 2005 and 2006...\n",
       "18      1.0  There's a reason why this stuff is significant...\n",
       "19      2.0  I was expecting a lot more from these two CD's...\n",
       "20      2.0  Acrobat 5 was so buggy that I thought I'd give...\n",
       "21      2.0  This software didn't quite do what I expected....\n",
       "22      1.0  Did not work with my apple computer,requested ...\n",
       "23      2.0  The computer I have now(about 500 Mhz)is faste...\n",
       "24      1.0  This is the first time I have ever reviewed a ...\n",
       "25      1.0  I purchased this software thinking that I coul...\n",
       "26      2.0  By reading the cover I thought it would be a g...\n",
       "27      1.0  Warning! I resized my partition and when it re...\n",
       "28      1.0  I have to qualify this review by saying that I...\n",
       "29      1.0  I purchased Partition Magic 8.0 based on my pr...\n",
       "..      ...                                                ...\n",
       "885     1.0  BE CAREFUL - If you buy this version of Symant...\n",
       "886     1.0  I Purchased this product in Nov 2006. Reviews ...\n",
       "887     1.0  This product is a huge waste of time.  It load...\n",
       "888     1.0  this software never worked after installation ...\n",
       "889     1.0  This software is fine for altering digital pic...\n",
       "890     1.0  this product is extremely difficult to learn. ...\n",
       "891     2.0  I received the bundle but there is no installa...\n",
       "892     2.0  ...buy it here and save $s!Shipping cost from ...\n",
       "893     1.0  I installed Adobe 8.0 at the request of a clie...\n",
       "894     2.0  Please see reviews of the previous version 7.0...\n",
       "895     1.0  TaxCut did not warn me that I needed to fill o...\n",
       "896     1.0  This program has a bug in processing 1099-R da...\n",
       "897     1.0  I got the hang on the 21% and all they could t...\n",
       "898     2.0  Unfortunately, this application includes only ...\n",
       "899     2.0  This dictionary is not for the person who Engl...\n",
       "900     1.0  I was thoroughly disappointed.  The first few ...\n",
       "901     1.0  This is the worst thing I have ever bought. I ...\n",
       "902     2.0  Although this dictionary's contents are extens...\n",
       "903     1.0  I have been using FrontPage since 1997.  I am ...\n",
       "904     1.0  I am not a 'professional,' but figured out how...\n",
       "905     2.0  I gave this a 2nd star for a support call ms p...\n",
       "906     1.0  Have tried about six times to install it.  I'v...\n",
       "907     1.0  i am underwhelmed with the dvd-rom from britan...\n",
       "908     1.0  EB own words: \"Unfortunately, at this time the...\n",
       "909     1.0  Since most of the complaints are from recent s...\n",
       "910     1.0  I've been using Quicken for Windows for years....\n",
       "911     1.0  Intuit charges banks extra to support Mac user...\n",
       "912     1.0  I purchased this product thinking that it woul...\n",
       "913     1.0  I've been using Quicken for over a decade, and...\n",
       "914     2.0  I have to agree with all these reviews already...\n",
       "\n",
       "[915 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negData_SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Automotive Reviews\n",
    "# posData_Automotive = pd.read_csv('.\\dataset\\Automotive\\md_Automotive_Positive.csv')\n",
    "# negData_Automotive = pd.read_csv('.\\dataset\\Automotive\\md_Automotive_Negative.csv')\n",
    "\n",
    "# #Cell Phones and Service reviews\n",
    "# posData_Cell = pd.read_csv('.\\dataset\\Cell_Phones_and_Service\\md_Cell_Phones_and_Service_Positive.csv')\n",
    "# negData_Cell = pd.read_csv('.\\dataset\\Cell_Phones_and_Service\\md_Cell_Phones_and_Service_Negative.csv')\n",
    "\n",
    "# #Electroncis Reviews\n",
    "# posData_Electronics = pd.read_csv('.\\dataset\\Electronics\\md_Electronics_Positive.csv')\n",
    "# negData_Electronics = pd.read_csv('.\\dataset\\Electronics\\md_Electronics_Negative.csv')\n",
    "\n",
    "# #Tools and Hardware reviews\n",
    "# posData_Tools = pd.read_csv('.\\dataset\\Tools_and_Hardware\\md_Tools_and_Hardware_Positive.csv')\n",
    "# negData_Tools = pd.read_csv('.\\dataset\\Tools_and_Hardware\\md_Tools_and_Hardware_Negative.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can extract the stopwords (given in dataset folder) to C:\\nltk_data\\corpora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords') #Or extract the stopwords to C:\\nltk_data\\corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myData = list(posData_SW.iloc[:, 1])+list(negData_SW.iloc[:, 1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myData = list(posData_SW.iloc[:, 1])+list(negData_SW.iloc[:, 1].values)+\\\n",
    "#         list(posData_Automotive.iloc[:, 2])+list(negData_Automotive.iloc[:, 2].values)+\\\n",
    "#         list(posData_Cell.iloc[:, 2])+list(negData_Cell.iloc[:, 2].values)+\\\n",
    "#         list(posData_Electronics.iloc[:, 2])+list(negData_Electronics.iloc[:, 2].values)+\\\n",
    "#         list(posData_Tools.iloc[:, 2])+list(negData_Tools.iloc[:, 2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1915"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(myData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am amazed what this program can do. It is a big difference from PS 5.5. It is a new learning curve but well worth it. What used to take me hours to do is now an action and done in 2 minutes. Amazon had the best price for me from a source I trust ordering from. It is worth it\n"
     ]
    }
   ],
   "source": [
    "print(myData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am amazed what this program can do  It is a big difference from PS      It is a new learning curve but well worth it  What used to take me hours to do is now an action and done in   minutes  Amazon had the best price for me from a source I trust ordering from  It is worth it\n"
     ]
    }
   ],
   "source": [
    "data = re.sub('[^a-zA-Z]', ' ', myData[0]) # Remove the special characheters and numbers\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am amazed what this program can do  it is a big difference from ps      it is a new learning curve but well worth it  what used to take me hours to do is now an action and done in   minutes  amazon had the best price for me from a source i trust ordering from  it is worth it\n"
     ]
    }
   ],
   "source": [
    "data = data.lower() # change to lower case letters\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'amazed', 'what', 'this', 'program', 'can', 'do', 'it', 'is', 'a', 'big', 'difference', 'from', 'ps', 'it', 'is', 'a', 'new', 'learning', 'curve', 'but', 'well', 'worth', 'it', 'what', 'used', 'to', 'take', 'me', 'hours', 'to', 'do', 'is', 'now', 'an', 'action', 'and', 'done', 'in', 'minutes', 'amazon', 'had', 'the', 'best', 'price', 'for', 'me', 'from', 'a', 'source', 'i', 'trust', 'ordering', 'from', 'it', 'is', 'worth', 'it']\n"
     ]
    }
   ],
   "source": [
    "data = data.split() # convert to list of words\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rem_stop_word(data):\n",
    "    data_processed =[]\n",
    "    for word in data:\n",
    "        if word not in stopwords.words('english'):\n",
    "            data_processed.append(word)\n",
    "    return data_processed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazed', 'program', 'big', 'difference', 'ps', 'new', 'learning', 'curve', 'well', 'worth', 'used', 'take', 'hours', 'action', 'done', 'minutes', 'amazon', 'best', 'price', 'source', 'trust', 'ordering', 'worth']\n"
     ]
    }
   ],
   "source": [
    "data = rem_stop_word(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Porter Stemmer](https://tartarus.org/martin/PorterStemmer/) <br>\n",
    "Porter stemmer is a process for removing the commoner morphological and inflexional endings from words in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amaz', 'program', 'big', 'differ', 'ps', 'new', 'learn', 'curv', 'well', 'worth', 'use', 'take', 'hour', 'action', 'done', 'minut', 'amazon', 'best', 'price', 'sourc', 'trust', 'order', 'worth']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer() #Porter Stemmer\n",
    "data = [ps.stem(word) for word in data]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amaz program big differ ps new learn curv well worth use take hour action done minut amazon best price sourc trust order worth'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ' '.join(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove special characters - \t I am amazed what this program can do  It is a big difference from PS      It is a new learning curve but well worth it  What used to take me hours to do is now an action and done in   minutes  Amazon had the best price for me from a source I trust ordering from  It is worth it\n",
      "To lower -\t\t\t i am amazed what this program can do  it is a big difference from ps      it is a new learning curve but well worth it  what used to take me hours to do is now an action and done in   minutes  amazon had the best price for me from a source i trust ordering from  it is worth it\n",
      "\n",
      "Split - \t\t\t ['i', 'am', 'amazed', 'what', 'this', 'program', 'can', 'do', 'it', 'is', 'a', 'big', 'difference', 'from', 'ps', 'it', 'is', 'a', 'new', 'learning', 'curve', 'but', 'well', 'worth', 'it', 'what', 'used', 'to', 'take', 'me', 'hours', 'to', 'do', 'is', 'now', 'an', 'action', 'and', 'done', 'in', 'minutes', 'amazon', 'had', 'the', 'best', 'price', 'for', 'me', 'from', 'a', 'source', 'i', 'trust', 'ordering', 'from', 'it', 'is', 'worth', 'it']\n",
      "\n",
      "Stopword Removal and Stemming -\t ['amaz', 'program', 'big', 'differ', 'ps', 'new', 'learn', 'curv', 'well', 'worth', 'use', 'take', 'hour', 'action', 'done', 'minut', 'amazon', 'best', 'price', 'sourc', 'trust', 'order', 'worth']\n",
      "\n",
      "Join\t\t\t\t amaz program big differ ps new learn curv well worth use take hour action done minut amazon best price sourc trust order worth\n"
     ]
    }
   ],
   "source": [
    "data = re.sub('[^a-zA-Z]', ' ', myData[0]) \n",
    "print('Remove special characters - \\t %s' % data)\n",
    "data = data.lower() # change to lower case letters\n",
    "print('To lower -\\t\\t\\t %s\\n'% data)\n",
    "data = data.split() # convert to list of words\n",
    "print('Split - \\t\\t\\t %s\\n' % data)\n",
    "ps = PorterStemmer()\n",
    "data = [ps.stem(word) for word in data if not word in stopwords.words('english')]\n",
    "print('Stopword Removal and Stemming -\\t %s\\n' % data)\n",
    "data = ' '.join(data)\n",
    "print('Join\\t\\t\\t\\t %s' % data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(myData)):\n",
    "    data = re.sub('[^a-zA-Z]', ' ', myData[i]) \n",
    "        #Keep only the characters from a to z\n",
    "        #[^a-zA-Z] to specify what is required in the review\n",
    "        # ' ' to replace removed characters with space \n",
    "    data = data.lower() # change to lower case letters\n",
    "    data = data.split() # convert to list of words\n",
    "    #data = rem_stop_word(data)\n",
    "    ps = PorterStemmer()\n",
    "    #data = [ps.stem(word) for word in data]\n",
    "    data = [ps.stem(word) for word in data if not word in set(stopwords.words('english'))]\n",
    "    # remove the stopwords ie. irrelevant words in the sentence for sentiment analysis\n",
    "    data = ' '.join(data) # join the words separated by space\n",
    "    corpus.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amaz program big differ ps new learn curv well worth use take hour action done minut amazon best price sourc trust order worth',\n",
       " 'concur review point problem adob new licens manag method activ pay much app entir suit face complet lockup hardwar problem connect internet locat shoot took one star egregi market tactic said version photoshop superb otherwis star app take time use tutori includ help use separ folder chapter classroom book ala get one deke mcclelland fine tome lesson noth app novic start use day one today point shoot camera pack resolut manual control function use photoshop becom hobbi realli rescu photo dark bright exceedingli color shift cut folder still make print camera raw function allow anyon suffici function digicam touch snapshot fine photographi warn need fastest processor afford core duo quatro superb much ram system take option perform plug maxim perform system gigabyt ram need least much window xp get good perform ps cs use gb dual channel memori even better dual channel ram add small boost handl larg file size e g camera raw imag sourc expect photoshop act fast adob bridg major improv version offer superior file imag manag function even batch edit imag even perform camera raw adjust right bridg bridg perform batch process edit photoshop cool know doubt check deke mcclelland photoshop cs one one tutori chapter use adob bridg video introduct includ dvd book chapter use custom bridg terrif introduct user version x upgrad cs brainer wait get adob licens manag get wors',\n",
       " 'simpli best softwar digit photograph graphic design anyth digit imag creation manipul pack featur novic profession advanc user limit imagin',\n",
       " 'adob photoshop long histori best softwar busi downsid may seem bit daunt begin user howev plethora text tutori learn guid even video help abat learn curv',\n",
       " 'afraid first order directli adob decid take cheaper rout obvious worth everyth arriv perfectli wrap origin cd set etc ship record time well eyal']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc 1:  I love dogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc 2:  I hate dogs and Knitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc 3:  Knitting is my hobby and my passion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/BoW1.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BoW - CountVectorizer](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=.0005,max_df=0.05, ngram_range=(1,1), max_features=feature_size)  \n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1915, 5000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define the target variable\n",
    "y = [1]*len(posData_SW) + [0]*len(negData_SW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Define the target variable\n",
    "# y = [1]*len(posData_SW) + [0]*len(negData_SW)+\\\n",
    "#     [1]*len(posData_Automotive) + [0]*len(negData_Automotive)+\\\n",
    "#     [1]*len(posData_Cell) + [0]*len(negData_Cell)+\\\n",
    "#     [1]*len(posData_Electronics) + [0]*len(negData_Electronics)+\\\n",
    "#     [1]*len(posData_Tools) + [0]*len(negData_Tools)\n",
    "# y=np.array(y)\n",
    "# #len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = X[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 576, 1600,  212, ...,  527, 1149, 1289])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into the Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_shuffled, y_shuffled, \\\n",
    "                                                    test_size = 0.20, random_state = 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ANN2.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define network\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(feature_size,), activation='relu'))\\\n",
    "#         kernel_regularizer=regularizers.l2(0.01),\\\n",
    "#         activity_regularizer=regularizers.l1(0.01)))#\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(Dense(128 , activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(512 , activation='relu', \\\n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy']) #adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                160032    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               16896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 177,441\n",
      "Trainable params: 177,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_shuffled, y_shuffled, test_size = 0.20, \\\n",
    "                                                    random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1532 samples, validate on 383 samples\n",
      "Epoch 1/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.9411 - acc: 0.6234 - val_loss: 0.7103 - val_acc: 0.7363\n",
      "Epoch 2/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.5114 - acc: 0.8610 - val_loss: 0.5438 - val_acc: 0.7833\n",
      "Epoch 3/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.2923 - acc: 0.9289 - val_loss: 0.5616 - val_acc: 0.8042\n",
      "Epoch 4/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.2009 - acc: 0.9582 - val_loss: 0.5744 - val_acc: 0.8120\n",
      "Epoch 5/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.1420 - acc: 0.9713 - val_loss: 0.6301 - val_acc: 0.8146\n",
      "Epoch 6/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.1072 - acc: 0.9824 - val_loss: 0.6816 - val_acc: 0.8120\n",
      "Epoch 7/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.0843 - acc: 0.9863 - val_loss: 0.7238 - val_acc: 0.7755\n",
      "Epoch 8/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.0665 - acc: 0.9922 - val_loss: 0.7428 - val_acc: 0.7963\n",
      "Epoch 9/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.0552 - acc: 0.9928 - val_loss: 0.8342 - val_acc: 0.8120\n",
      "Epoch 10/10\n",
      "1532/1532 [==============================] - 0s - loss: 0.0566 - acc: 0.9909 - val_loss: 0.8303 - val_acc: 0.8042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19c53cf8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32,verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.417754\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred=model.predict_classes(X_test, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[128,  45],\n",
       "       [ 30, 180]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(myReview):\n",
    "    result = []\n",
    "    myReview = re.sub('[^a-zA-Z]', ' ', myReview) \n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    myReview = myReview.lower() # change to lower case letters\n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    myReview = myReview.split(' ') # convert to list of words\n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    myReview= list(filter(None, myReview)) #remove empty strings\n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    myReview = rem_stop_word(myReview)\n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    myReview = [ps.stem(word) for word in myReview]\n",
    "    print(myReview,'\\n')\n",
    "\n",
    "    myReview = ' '.join(myReview)\n",
    "    print(myReview,'\\n')\n",
    "    \n",
    "    result.append(myReview)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myReview = input('Enter Review: ')\n",
    "myReview = '''Adobe Photoshop has a long history of being the best software in the business.  \n",
    "It's only downside is that it may seem a bit daunting to the beginning user.\n",
    "There is, however, a plethora of texts, tutorials, learning guides, and even video's to help abate the learning curve'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adobe Photoshop has a long history of being the best software in the business    It s only downside is that it may seem a bit daunting to the beginning user  There is  however  a plethora of texts  tutorials  learning guides  and even video s to help abate the learning curve \n",
      "\n",
      "adobe photoshop has a long history of being the best software in the business    it s only downside is that it may seem a bit daunting to the beginning user  there is  however  a plethora of texts  tutorials  learning guides  and even video s to help abate the learning curve \n",
      "\n",
      "['adobe', 'photoshop', 'has', 'a', 'long', 'history', 'of', 'being', 'the', 'best', 'software', 'in', 'the', 'business', '', '', '', 'it', 's', 'only', 'downside', 'is', 'that', 'it', 'may', 'seem', 'a', 'bit', 'daunting', 'to', 'the', 'beginning', 'user', '', 'there', 'is', '', 'however', '', 'a', 'plethora', 'of', 'texts', '', 'tutorials', '', 'learning', 'guides', '', 'and', 'even', 'video', 's', 'to', 'help', 'abate', 'the', 'learning', 'curve'] \n",
      "\n",
      "['adobe', 'photoshop', 'has', 'a', 'long', 'history', 'of', 'being', 'the', 'best', 'software', 'in', 'the', 'business', 'it', 's', 'only', 'downside', 'is', 'that', 'it', 'may', 'seem', 'a', 'bit', 'daunting', 'to', 'the', 'beginning', 'user', 'there', 'is', 'however', 'a', 'plethora', 'of', 'texts', 'tutorials', 'learning', 'guides', 'and', 'even', 'video', 's', 'to', 'help', 'abate', 'the', 'learning', 'curve'] \n",
      "\n",
      "['adobe', 'photoshop', 'long', 'history', 'best', 'software', 'business', 'downside', 'may', 'seem', 'bit', 'daunting', 'beginning', 'user', 'however', 'plethora', 'texts', 'tutorials', 'learning', 'guides', 'even', 'video', 'help', 'abate', 'learning', 'curve'] \n",
      "\n",
      "['adob', 'photoshop', 'long', 'histori', 'best', 'softwar', 'busi', 'downsid', 'may', 'seem', 'bit', 'daunt', 'begin', 'user', 'howev', 'plethora', 'text', 'tutori', 'learn', 'guid', 'even', 'video', 'help', 'abat', 'learn', 'curv'] \n",
      "\n",
      "adob photoshop long histori best softwar busi downsid may seem bit daunt begin user howev plethora text tutori learn guid even video help abat learn curv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testReview=preprocessing(myReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adob photoshop long histori best softwar busi downsid may seem bit daunt begin user howev plethora text tutori learn guid even video help abat learn curv']\n"
     ]
    }
   ],
   "source": [
    "print(testReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(testReview).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\tPrediction is POSITIVE\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "if (model.predict_classes(cv.transform(testReview).toarray(), verbose=0))==1:\n",
    "    print('='*40+\"\\n\\tPrediction is POSITIVE\\n\"+'='*40)\n",
    "else:\n",
    "    print('='*40+\"\\n\\tPrediction is NEGATIVE\\n\"+'='*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/CNN1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv1D(32, kernel_size=5,\n",
    "                 activation='relu',\n",
    "                 input_shape=(feature_size,1)))\n",
    "model1.add(Conv1D(16, kernel_size=5,\n",
    "                 activation='relu',\n",
    "                 input_shape=(feature_size,1)))\n",
    "model1.add(MaxPooling1D(pool_size=(8)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(MaxPooling1D(pool_size=(8)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "# model1.add(Dropout(0.25))\n",
    "# model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 4996, 32)          192       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 4992, 16)          2576      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 624, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 624, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 78, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 78, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1248)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                39968     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 42,769\n",
      "Trainable params: 42,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_shuffled, y_shuffled, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1532, 5000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1532, 5000, 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape+(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1532, 5000, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_CNN=X_train.reshape(X_train.shape+(1,))\n",
    "y_train_CNN=y_train.reshape(y_train.shape+(1,))\n",
    "X_test_CNN=X_test.reshape(X_test.shape+(1,))\n",
    "y_test_CNN=y_test.reshape(y_test.shape+(1,))\n",
    "X_train_CNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1532 samples, validate on 383 samples\n",
      "Epoch 1/10\n",
      "1532/1532 [==============================] - 15s - loss: 0.6911 - acc: 0.5463 - val_loss: 0.6807 - val_acc: 0.6371\n",
      "Epoch 2/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.6685 - acc: 0.6260 - val_loss: 0.6581 - val_acc: 0.6606\n",
      "Epoch 3/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.6348 - acc: 0.6782 - val_loss: 0.6459 - val_acc: 0.6423\n",
      "Epoch 4/10\n",
      "1532/1532 [==============================] - 13s - loss: 0.6267 - acc: 0.6736 - val_loss: 0.6372 - val_acc: 0.6527\n",
      "Epoch 5/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.6314 - acc: 0.6638 - val_loss: 0.6354 - val_acc: 0.6449\n",
      "Epoch 6/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.6019 - acc: 0.6880 - val_loss: 0.6345 - val_acc: 0.6449\n",
      "Epoch 7/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.5854 - acc: 0.6958 - val_loss: 0.6295 - val_acc: 0.6580\n",
      "Epoch 8/10\n",
      "1532/1532 [==============================] - 15s - loss: 0.5885 - acc: 0.6991 - val_loss: 0.6238 - val_acc: 0.6580\n",
      "Epoch 9/10\n",
      "1532/1532 [==============================] - 15s - loss: 0.5643 - acc: 0.7154 - val_loss: 0.6182 - val_acc: 0.6867\n",
      "Epoch 10/10\n",
      "1532/1532 [==============================] - 14s - loss: 0.5660 - acc: 0.7180 - val_loss: 0.6136 - val_acc: 0.6527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18d2c9e8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train_CNN, y_train_CNN,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_CNN, y_test_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.613617814396\n",
      "Test accuracy: 0.652741512804\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.274151\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model1.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred_CNN=model1.predict_classes(X_test_CNN, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109,  73],\n",
       "       [ 60, 141]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test_CNN, y_pred_CNN)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp=cv.transform(testReview).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5000, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.reshape(temp.shape+(1,)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "\tPrediction is POSITIVE\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "if (model1.predict_classes(temp.reshape(temp.shape+(1,)), verbose=0))==1:\n",
    "    print('='*40+\"\\n\\tPrediction is POSITIVE\\n\"+'='*40)\n",
    "else:\n",
    "    print('='*40+\"\\n\\tPrediction is NEGATIVE\\n\"+'='*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
